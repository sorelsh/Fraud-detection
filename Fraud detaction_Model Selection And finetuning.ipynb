{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5d32a2-5474-4a6c-ba87-12bff2915abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693ccd3f-d15e-4c0c-8899-f23cbc4729d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_pickle(r'C:\\Course\\Repo\\Fraud detection\\Files\\df_model_data_after_FeatureEngineering_23.3.25.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3640af47-f905-482d-acc8-dc8048ba8cfb",
   "metadata": {},
   "source": [
    "#### <font color='Indigo'>Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c56b986b-7bbf-4cf7-879a-9e76c1c50662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 70.00%\n",
      "Validation (Dev) set size: 15.00%\n",
      "Testing set size: 15.00%\n"
     ]
    }
   ],
   "source": [
    "# Define the target and feature set\n",
    "X = df_model.drop(columns=['is_fraud'])\n",
    "X = X.astype({col: 'float64' for col in X.select_dtypes(include=['Int64']).columns})\n",
    "y = df_model['is_fraud']\n",
    "\n",
    "# Total number of samples\n",
    "total_samples = len(df_model)\n",
    "\n",
    "# First split: training and temporary (test + dev)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: testing and development (dev)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Calculate percentages\n",
    "train_percent = (X_train.shape[0] / total_samples) * 100\n",
    "dev_percent = (X_dev.shape[0] / total_samples) * 100\n",
    "test_percent = (X_test.shape[0] / total_samples) * 100\n",
    "\n",
    "# Output the sizes of each set in percentages\n",
    "print(f\"Training set size: {train_percent:.2f}%\")\n",
    "print(f\"Validation (Dev) set size: {dev_percent:.2f}%\")\n",
    "print(f\"Testing set size: {test_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebc4381-7dd4-47d7-9a70-2481b9845b6b",
   "metadata": {},
   "source": [
    "## üü¶‚öñÔ∏èüü•Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "347d5536-cfb9-4507-b7d7-11f814f74e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           count  percentage\n",
      "is_fraud                    \n",
      "0         298333       99.44\n",
      "1           1667        0.56\n"
     ]
    }
   ],
   "source": [
    "# Get counts\n",
    "fraud_counts = df_model['is_fraud'].value_counts()\n",
    "\n",
    "# Get ratios (proportions)\n",
    "fraud_ratios = df_model['is_fraud'].value_counts(normalize=True).round(4) * 100  # multiply by 100 for percentage\n",
    "\n",
    "# Combine counts and ratios into a DataFrame\n",
    "fraud_summary = pd.DataFrame({\n",
    "    'count': fraud_counts,\n",
    "    'percentage': fraud_ratios\n",
    "})\n",
    "print(fraud_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b167e2d-f915-4419-a6f6-850f8740ca36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the counts for is_fraud\n",
    "fraud_counts = df_model['is_fraud'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(fraud_counts.index.astype(str), fraud_counts.values, color=['skyblue', 'salmon'])\n",
    "plt.xlabel('Is Fraud')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Fraud Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "753a9ffc-e38d-410a-9c2f-bfedbd0d183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Baseline (no resampling)...\n",
      "Performance of Baseline on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     44739\n",
      "           1       0.91      0.85      0.88       261\n",
      "\n",
      "    accuracy                           1.00     45000\n",
      "   macro avg       0.95      0.92      0.94     45000\n",
      "weighted avg       1.00      1.00      1.00     45000\n",
      "\n",
      "F1-score: 0.8752475247524752\n",
      "\n",
      "[[44716    23]\n",
      " [   40   221]]\n",
      "--------------------------------------------------------------------------------\n",
      "Applying ROS...\n",
      "Shape of resampled training data (after ROS): Counter({0: 208827, 1: 208827})\n",
      "Performance of ROS on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     44739\n",
      "           1       0.92      0.82      0.86       261\n",
      "\n",
      "    accuracy                           1.00     45000\n",
      "   macro avg       0.96      0.91      0.93     45000\n",
      "weighted avg       1.00      1.00      1.00     45000\n",
      "\n",
      "F1-score: 0.8640973630831643\n",
      "\n",
      "[[44720    19]\n",
      " [   48   213]]\n",
      "--------------------------------------------------------------------------------\n",
      "Applying RUS...\n",
      "Shape of resampled training data (after RUS): Counter({0: 1173, 1: 1173})\n",
      "Performance of RUS on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98     44739\n",
      "           1       0.11      0.93      0.19       261\n",
      "\n",
      "    accuracy                           0.95     45000\n",
      "   macro avg       0.55      0.94      0.58     45000\n",
      "weighted avg       0.99      0.95      0.97     45000\n",
      "\n",
      "F1-score: 0.19077404222048475\n",
      "\n",
      "[[42686  2053]\n",
      " [   17   244]]\n",
      "--------------------------------------------------------------------------------\n",
      "Applying SMOTE...\n",
      "Shape of resampled training data (after SMOTE): Counter({0: 208827, 1: 208827})\n",
      "Performance of SMOTE on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     44739\n",
      "           1       0.60      0.87      0.71       261\n",
      "\n",
      "    accuracy                           1.00     45000\n",
      "   macro avg       0.80      0.93      0.85     45000\n",
      "weighted avg       1.00      1.00      1.00     45000\n",
      "\n",
      "F1-score: 0.710691823899371\n",
      "\n",
      "[[44590   149]\n",
      " [   35   226]]\n",
      "--------------------------------------------------------------------------------\n",
      "Applying ADASYN...\n",
      "Shape of resampled training data (after ADASYN): Counter({1: 209277, 0: 208827})\n",
      "Performance of ADASYN on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     44739\n",
      "           1       0.60      0.87      0.71       261\n",
      "\n",
      "    accuracy                           1.00     45000\n",
      "   macro avg       0.80      0.93      0.85     45000\n",
      "weighted avg       1.00      1.00      1.00     45000\n",
      "\n",
      "F1-score: 0.70625\n",
      "\n",
      "[[44586   153]\n",
      " [   35   226]]\n",
      "--------------------------------------------------------------------------------\n",
      "Applying BorderlineSMOTE...\n",
      "Shape of resampled training data (after BorderlineSMOTE): Counter({0: 208827, 1: 208827})\n",
      "Performance of BorderlineSMOTE on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     44739\n",
      "           1       0.64      0.88      0.74       261\n",
      "\n",
      "    accuracy                           1.00     45000\n",
      "   macro avg       0.82      0.94      0.87     45000\n",
      "weighted avg       1.00      1.00      1.00     45000\n",
      "\n",
      "F1-score: 0.7387096774193549\n",
      "\n",
      "[[44609   130]\n",
      " [   32   229]]\n",
      "--------------------------------------------------------------------------------\n",
      "Applying SMOTETomek...\n",
      "Shape of resampled training data (after SMOTETomek): Counter({0: 208787, 1: 208787})\n",
      "Performance of SMOTETomek on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     44739\n",
      "           1       0.60      0.84      0.70       261\n",
      "\n",
      "    accuracy                           1.00     45000\n",
      "   macro avg       0.80      0.92      0.85     45000\n",
      "weighted avg       1.00      1.00      1.00     45000\n",
      "\n",
      "F1-score: 0.7028753993610224\n",
      "\n",
      "[[44594   145]\n",
      " [   41   220]]\n",
      "--------------------------------------------------------------------------------\n",
      "The best technique based on F1-score is: Baseline\n",
      "Performance of the best technique (Baseline):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     44739\n",
      "           1       0.91      0.85      0.88       261\n",
      "\n",
      "    accuracy                           1.00     45000\n",
      "   macro avg       0.95      0.92      0.94     45000\n",
      "weighted avg       1.00      1.00      1.00     45000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the resampling techniques\n",
    "resampling_techniques = {\n",
    "    'ROS': RandomOverSampler(random_state=42),\n",
    "    'RUS': RandomUnderSampler(random_state=42),\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'ADASYN': ADASYN(random_state=42),\n",
    "    'BorderlineSMOTE': BorderlineSMOTE(random_state=42),\n",
    "    'SMOTETomek': SMOTETomek(random_state=42),\n",
    "    # 'TomekLinks': TomekLinks()  # Uncomment to include this technique\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Define the model with random_state for reproducibility\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# **Baseline Test: No resampling**\n",
    "print(\"Applying Baseline (no resampling)...\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "f1_score_val = f1_score(y_test, y_pred)\n",
    "results['Baseline'] = {'classification_report': report, 'f1_score': f1_score_val}\n",
    "print(f\"Performance of Baseline on the test set:\\n{report}\")\n",
    "print(f\"F1-score: {f1_score_val}\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Iterate through each resampling technique\n",
    "for name, resampler in resampling_techniques.items():\n",
    "    print(f\"Applying {name}...\")\n",
    "    # Resample the training data\n",
    "    X_resampled, y_resampled = resampler.fit_resample(X_train, y_train)\n",
    "    print(f\"Shape of resampled training data (after {name}): {Counter(y_resampled)}\")\n",
    "    \n",
    "    # Train the model on the resampled training data\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the performance\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    f1_score_val = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {'classification_report': report, 'f1_score': f1_score_val}\n",
    "    print(f\"Performance of {name} on the test set:\\n{report}\")\n",
    "    print(f\"F1-score: {f1_score_val}\\n\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Find the best technique based on F1-score (including Baseline)\n",
    "best_technique = max(results, key=lambda k: results[k]['f1_score'])\n",
    "print(f\"The best technique based on F1-score is: {best_technique}\")\n",
    "print(f\"Performance of the best technique ({best_technique}):\\n{results[best_technique]['classification_report']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6285f84-48fc-448c-9374-031932e60563",
   "metadata": {},
   "source": [
    "### <br>\n",
    "##  <font color='yellow'>‚öñÔ∏èResampling Strategy Comparison Report\n",
    "\n",
    "### Overview\n",
    "In an effort to improve my credit card fraud detection model‚Äîgiven the severe class imbalance (only 0.56% fraud)‚ÄîI evaluated several resampling techniques. These included:\n",
    "- **Baseline (No Resampling)**\n",
    "- **Random Over Sampling (ROS)**\n",
    "- **Random Under Sampling (RUS)**\n",
    "- **SMOTE**\n",
    "- **ADASYN**\n",
    "- **BorderlineSMOTE**\n",
    "- **SMOTETomek**\n",
    "\n",
    "### Experimental Results Summary\n",
    "\n",
    "- **Baseline (No Resampling)**:\n",
    "  - **F1-score:** 0.875\n",
    "  - **Confusion Matrix:**  \n",
    "    ```\n",
    "    [[44716    23]\n",
    "     [   40   221]]\n",
    "    ```\n",
    "  - **Observations:** The classifier already performed robustly on the imbalanced data with high precision and recall for the minority class.\n",
    "\n",
    "- **Random Over Sampling (ROS)**:\n",
    "  - **F1-score:** 0.864\n",
    "  - **Confusion Matrix:**  \n",
    "    ```\n",
    "    [[44720    19]\n",
    "     [   48   213]]\n",
    "    ```\n",
    "  - **Observations:** While ROS balanced the training data, the performance slightly dropped compared to the baseline, suggesting that the model‚Äôs current capacity is sufficient to handle the imbalance.\n",
    "\n",
    "- **Other Resampling Techniques**:\n",
    "  - **RUS, SMOTE, ADASYN, BorderlineSMOTE, and SMOTETomek** all resulted in lower F1-scores (ranging from 0.19 to 0.738).\n",
    "  - **Observations:** These methods either significantly reduced performance (e.g., RUS with an F1-score of 0.19) or did not improve upon the baseline, likely due to overfitting or loss of important signal in the minority class.\n",
    "\n",
    "### Rationale for Choosing Baseline and ROS\n",
    "\n",
    "- **Baseline as the Best Performer:**  \n",
    "  The Baseline model, without any resampling, achieved the highest F1-score of 0.875. This indicates that the decision tree classifier is capable of effectively handling the imbalance in the data, and any additional resampling might be unnecessary or even detrimental.\n",
    "\n",
    "- **ROS for Comparison:**  \n",
    "  Although ROS slightly reduced the F1-score (0.864), its performance is still comparable to the Baseline. ROS is simple to implement and maintains the original data characteristics, making it a good candidate for further comparative studies in more complex modeling scenarios.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Based on our experimental results:\n",
    "- The **Baseline** approach is the most effective for this particular dataset.\n",
    "- **ROS** is selected as the next best method for comparison, due to its simplicity and relatively similar performance.\n",
    "- More complex resampling techniques did not yield improvements and, in some cases, degraded the model performance.\n",
    "\n",
    "These insights will help in focusing further model development and tuning on approaches that either retain the original data distribution or make minimal modifications (such as ROS), rather than more aggressive resampling strategies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e4581c0-98a6-4e79-ba22-5fc558b43f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11e6a55-a6f3-45cd-b7e8-29ee946383be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d04618d2-14b1-4098-81b9-d48e4fdf70db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e7fcb-7eed-4518-8168-c3efc4d5abc5",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91c590bd-e989-455d-b27c-5cc4c52b667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_model_selection(X_train, X_test, y_train, y_test, dataset_name=\"\"):\n",
    "    \"\"\"\n",
    "    Performs classifier model selection on the given dataset.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame or np.ndarray): Training features.\n",
    "        X_test (pd.DataFrame or np.ndarray): Testing features.\n",
    "        y_train (pd.Series or np.ndarray): Training target.\n",
    "        y_test (pd.Series or np.ndarray): Testing target.\n",
    "        dataset_name (str, optional): Name of the dataset for output labeling. Defaults to \"\".\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Performing Model Selection on: {dataset_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Define classifiers\n",
    "    classifiers = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, solver='liblinear'),\n",
    "        #'Support Vector Machine': SVC(random_state=42),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "        'Naive Bayes': GaussianNB()\n",
    "    }\n",
    "\n",
    "    # Evaluation metric: F1 Score\n",
    "    scoring_metric = make_scorer(f1_score)\n",
    "\n",
    "    # Cross-validation setup\n",
    "    n_folds = 5\n",
    "    cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Cross-validation results\n",
    "    cv_results = {}\n",
    "\n",
    "    print(\"Performing cross-validation...\")\n",
    "    for name, clf in classifiers.items():\n",
    "        print(f\"Evaluating {name}...\")\n",
    "        scores = cross_val_score(clf, X_train_scaled, y_train, cv=cv, scoring=scoring_metric, n_jobs=-1, error_score='raise')\n",
    "        cv_results[name] = scores.mean()\n",
    "\n",
    "    print(\"\\nCross-Validation Results (Mean F1-Score):\")\n",
    "    for name, score in sorted(cv_results.items(), key=lambda item: item[1], reverse=True):\n",
    "        print(f\"{name}: {score:.4f}\")\n",
    "\n",
    "    # Select best model based on cross-validation performance\n",
    "    best_model_name = max(cv_results, key=cv_results.get)\n",
    "    best_model = classifiers[best_model_name]\n",
    "    print(f\"\\nBest model based on cross-validation: {best_model_name}\")\n",
    "\n",
    "    # Train best model using the scaled training data\n",
    "    best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate best model on the test set\n",
    "    print(\"\\nEvaluation of the Best Model on the Test Set:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # If the classifier supports probability estimates, calculate ROC AUC Score\n",
    "    if hasattr(best_model, \"predict_proba\"):\n",
    "        y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nROC AUC Score not available for this classifier.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb9965-c0b3-4f42-a5d2-bc927c9e2ca5",
   "metadata": {},
   "source": [
    "#### <font color='Indigo'> Perform model selection on the original imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c7b390d-fa8e-404b-937f-4ce219fc4d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Performing Model Selection on: Original Imbalanced Dataset\n",
      "==================================================\n",
      "Performing cross-validation...\n",
      "Evaluating Logistic Regression...\n",
      "Evaluating Support Vector Machine...\n",
      "Evaluating Decision Tree...\n",
      "Evaluating Random Forest...\n",
      "Evaluating Gradient Boosting...\n",
      "Evaluating Naive Bayes...\n",
      "\n",
      "Cross-Validation Results (Mean F1-Score):\n",
      "Random Forest: 0.9184\n",
      "Gradient Boosting: 0.9047\n",
      "Decision Tree: 0.8790\n",
      "Support Vector Machine: 0.6653\n",
      "Naive Bayes: 0.3704\n",
      "Logistic Regression: 0.2313\n",
      "\n",
      "Best model based on cross-validation: Random Forest\n",
      "\n",
      "Evaluation of the Best Model on the Test Set:\n",
      "[[44739     0]\n",
      " [   49   212]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     44739\n",
      "           1       1.00      0.81      0.90       261\n",
      "\n",
      "    accuracy                           1.00     45000\n",
      "   macro avg       1.00      0.91      0.95     45000\n",
      "weighted avg       1.00      1.00      1.00     45000\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.9934\n"
     ]
    }
   ],
   "source": [
    "perform_model_selection(X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy(), dataset_name=\"Original Imbalanced Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e73c9-8e9a-4097-be11-ef7f139c868a",
   "metadata": {},
   "source": [
    "#### <font color='Indigo'> Perform model selection on the balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c6a95f9-0d5b-4221-a67f-b4adbedc0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying Random Over-Sampling for handling class imbalance...\n",
      "Original class distribution: is_fraud\n",
      "0    298333\n",
      "1      1667\n",
      "Name: count, dtype: int64\n",
      "Class distribution after Random Over-Sampling: is_fraud\n",
      "0    298333\n",
      "1    298333\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "Performing Model Selection on: Dataset with Random Over-Sampling\n",
      "==================================================\n",
      "Performing cross-validation...\n",
      "Evaluating Logistic Regression...\n",
      "Evaluating Decision Tree...\n",
      "Evaluating Random Forest...\n",
      "Evaluating Gradient Boosting...\n",
      "Evaluating Naive Bayes...\n",
      "\n",
      "Cross-Validation Results (Mean F1-Score):\n",
      "Random Forest: 1.0000\n",
      "Decision Tree: 0.9995\n",
      "Gradient Boosting: 0.9857\n",
      "Logistic Regression: 0.9209\n",
      "Naive Bayes: 0.8667\n",
      "\n",
      "Best model based on cross-validation: Random Forest\n",
      "\n",
      "Evaluation of the Best Model on the Test Set:\n",
      "[[44506     1]\n",
      " [    0 44993]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     44507\n",
      "           1       1.00      1.00      1.00     44993\n",
      "\n",
      "    accuracy                           1.00     89500\n",
      "   macro avg       1.00      1.00      1.00     89500\n",
      "weighted avg       1.00      1.00      1.00     89500\n",
      "\n",
      "\n",
      "ROC AUC Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Handle class imbalance using Random Over-Sampling\n",
    "print(\"\\nApplying Random Over-Sampling for handling class imbalance...\")\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "print(f\"Original class distribution: {y.value_counts()}\")\n",
    "print(f\"Class distribution after Random Over-Sampling: {y_resampled.value_counts()}\")\n",
    "\n",
    "# First split: training and temporary (test + dev)\n",
    "X_train_resampled, X_temp_resampled, y_train_resampled, y_temp_resampled = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "# Second split: testing and development (dev)\n",
    "X_dev_resampled, X_test_resampled, y_dev_resampled, y_test_resampled = train_test_split(X_temp_resampled, y_temp_resampled, test_size=0.5, random_state=42)\n",
    "# Perform model selection on the balanced dataset\n",
    "perform_model_selection(X_train_resampled.copy(), X_test_resampled.copy(), y_train_resampled.copy(), y_test_resampled.copy(), dataset_name=\"Dataset with Random Over-Sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb1844-b535-4294-9e3e-f3d2d0191552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b45f3-6657-4bb8-a73a-e01fe0792856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fine-tuning RandomForestClassifier ---\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Optional: Feature Scaling (can be helpful for GradientBoosting) ---\n",
    "#scaler = StandardScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "#X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "#X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "# --- End of Optional Scaling ---\n",
    "\n",
    "# Define the parameter grids for fine-tuning\n",
    "\n",
    "# RandomForestClassifier parameters to tune\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# GradientBoostingClassifier parameters to tune\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Define the scoring metric for evaluation (consider F1-score for the minority class - fraud)\n",
    "scoring_metric = 'f1'  # Or 'f1_weighted' or a custom scorer\n",
    "\n",
    "# For imbalanced datasets like credit card fraud, StratifiedKFold is crucial\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# --- Fine-tuning RandomForestClassifier ---\n",
    "print(\"--- Fine-tuning RandomForestClassifier ---\")\n",
    "rf_grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                               param_grid=rf_param_grid,\n",
    "                               scoring=scoring_metric,\n",
    "                               cv=cv,\n",
    "                               n_jobs=-1,  # Use all available cores\n",
    "                               verbose=2)\n",
    "\n",
    "rf_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters for RandomForestClassifier:\", rf_grid_search.best_params_)\n",
    "print(\"Best cross-validation score for RandomForestClassifier:\", rf_grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best RandomForestClassifier model on the test set\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test_resampled)\n",
    "print(\"\\nClassification Report for Best RandomForestClassifier (Test Set):\")\n",
    "print(classification_report(y_test_resampled, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix for Best RandomForestClassifier (Test Set):\")\n",
    "print(confusion_matrix(y_test_resampled, y_pred_rf))\n",
    "\n",
    "# Calculate AUC on the test set\n",
    "y_pred_proba_rf = best_rf_model.predict_proba(X_test_resampled)[:, 1]\n",
    "roc_auc_rf = roc_auc_score(y_test_resampled, y_pred_proba_rf)\n",
    "print(f\"\\nAUC for Best RandomForestClassifier (Test Set): {roc_auc_rf:.4f}\")\n",
    "\n",
    "# --- Fine-tuning GradientBoostingClassifier ---\n",
    "print(\"\\n--- Fine-tuning GradientBoostingClassifier ---\")\n",
    "gb_grid_search = GridSearchCV(estimator=GradientBoostingClassifier(random_state=42),\n",
    "                               param_grid=gb_param_grid,\n",
    "                               scoring=scoring_metric,\n",
    "                               cv=cv,\n",
    "                               n_jobs=-1,  # Use all available cores\n",
    "                               verbose=2)\n",
    "\n",
    "gb_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters for GradientBoostingClassifier:\", gb_grid_search.best_params_)\n",
    "print(\"Best cross-validation score for GradientBoostingClassifier:\", gb_grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best GradientBoostingClassifier model on the test set\n",
    "best_gb_model = gb_grid_search.best_estimator_\n",
    "y_pred_gb = best_gb_model.predict(X_test_resampled)\n",
    "print(\"\\nClassification Report for Best GradientBoostingClassifier (Test Set):\")\n",
    "print(classification_report(y_test_resampled, y_pred_gb))\n",
    "print(\"\\nConfusion Matrix for Best GradientBoostingClassifier (Test Set):\")\n",
    "print(confusion_matrix(y_test_resampled, y_pred_gb))\n",
    "\n",
    "# Calculate AUC on the test set\n",
    "y_pred_proba_gb = best_gb_model.predict_proba(X_test_resampled)[:, 1]\n",
    "roc_auc_gb = roc_auc_score(y_test_resampled, y_pred_proba_gb)\n",
    "print(f\"\\nAUC for Best GradientBoostingClassifier (Test Set): {roc_auc_gb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d34370-5936-4dbd-8db4-787ee8b8e721",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2eabaa-7c03-40bd-b2f5-9430ce1d2f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
